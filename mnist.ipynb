{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poorya0071/Classification/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST\n",
        "The aim of this project is to find the best model for Mnist dataset."
      ],
      "metadata": {
        "id": "mpD3ZDi0ULLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SDTc4lvqpWk4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ3nzne2pPy8",
        "outputId": "246dc3b5-b13f-4f38-b56c-cd78b703b1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwPGfwapmxV",
        "outputId": "6592ee13-fbcb-4665-f287-3efbc1ba0070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000, 60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(train_data), len(test_data), len(train_labels), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "h5Kralv2pY7Q",
        "outputId": "e3159d67-6594-4466-c0ac-87e0f63d4ac5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcf446bd9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXFDRtchpfg4",
        "outputId": "9ef75296-855e-46b3-d820-a6605ebd0278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale the dataset"
      ],
      "metadata": {
        "id": "sWWS3vJKUVxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data/255"
      ],
      "metadata": {
        "id": "aCopY4g-B7MU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_scaled = test_data/255"
      ],
      "metadata": {
        "id": "9piOcYEYCCO6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQK120UqLCa",
        "outputId": "e07313dd-bf9b-4d8e-9410-69cfa08210a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
              "      dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_labels[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gh0CGnVnpyCt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "label_data = pd.DataFrame(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FwIrAqWp6Uh",
        "outputId": "4be4b9c9-ce4d-4d9b-e772-885ce4f84f9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6000\n",
              "1    6000\n",
              "2    6000\n",
              "3    6000\n",
              "4    6000\n",
              "5    6000\n",
              "6    6000\n",
              "7    6000\n",
              "8    6000\n",
              "9    6000\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "label_data.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medel_0: Dense model increasing layers from 16 to 64, LR= 0.0001\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zC8astVBVI7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh92gH2IqF7i",
        "outputId": "ac7ecd81-55fd-4aed-f8c7-d4bc3dff4619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9690 - accuracy: 0.6675 - val_loss: 0.6537 - val_accuracy: 0.7714\n",
            "Epoch 2/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5705 - accuracy: 0.8034 - val_loss: 0.5511 - val_accuracy: 0.8110\n",
            "Epoch 3/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4994 - accuracy: 0.8284 - val_loss: 0.5114 - val_accuracy: 0.8215\n",
            "Epoch 4/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4661 - accuracy: 0.8388 - val_loss: 0.4837 - val_accuracy: 0.8342\n",
            "Epoch 5/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4463 - accuracy: 0.8451 - val_loss: 0.4726 - val_accuracy: 0.8341\n",
            "Epoch 6/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4315 - accuracy: 0.8494 - val_loss: 0.4658 - val_accuracy: 0.8364\n",
            "Epoch 7/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4200 - accuracy: 0.8536 - val_loss: 0.4609 - val_accuracy: 0.8389\n",
            "Epoch 8/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4096 - accuracy: 0.8570 - val_loss: 0.4432 - val_accuracy: 0.8451\n",
            "Epoch 9/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4019 - accuracy: 0.8602 - val_loss: 0.4360 - val_accuracy: 0.8481\n",
            "Epoch 10/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3952 - accuracy: 0.8613 - val_loss: 0.4293 - val_accuracy: 0.8500\n",
            "Epoch 11/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3893 - accuracy: 0.8637 - val_loss: 0.4229 - val_accuracy: 0.8527\n",
            "Epoch 12/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3818 - accuracy: 0.8654 - val_loss: 0.4244 - val_accuracy: 0.8498\n",
            "Epoch 13/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3777 - accuracy: 0.8667 - val_loss: 0.4170 - val_accuracy: 0.8541\n",
            "Epoch 14/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3724 - accuracy: 0.8686 - val_loss: 0.4134 - val_accuracy: 0.8543\n",
            "Epoch 15/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3677 - accuracy: 0.8698 - val_loss: 0.4147 - val_accuracy: 0.8533\n",
            "Epoch 16/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3644 - accuracy: 0.8712 - val_loss: 0.4056 - val_accuracy: 0.8577\n",
            "Epoch 17/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3602 - accuracy: 0.8733 - val_loss: 0.4040 - val_accuracy: 0.8576\n",
            "Epoch 18/60\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3577 - accuracy: 0.8727 - val_loss: 0.4048 - val_accuracy: 0.8591\n",
            "Epoch 19/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3542 - accuracy: 0.8751 - val_loss: 0.4026 - val_accuracy: 0.8594\n",
            "Epoch 20/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3516 - accuracy: 0.8755 - val_loss: 0.4019 - val_accuracy: 0.8589\n",
            "Epoch 21/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3479 - accuracy: 0.8765 - val_loss: 0.3998 - val_accuracy: 0.8601\n",
            "Epoch 22/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3448 - accuracy: 0.8780 - val_loss: 0.3959 - val_accuracy: 0.8622\n",
            "Epoch 23/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3431 - accuracy: 0.8797 - val_loss: 0.3954 - val_accuracy: 0.8622\n",
            "Epoch 24/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3412 - accuracy: 0.8788 - val_loss: 0.3972 - val_accuracy: 0.8615\n",
            "Epoch 25/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3385 - accuracy: 0.8801 - val_loss: 0.3981 - val_accuracy: 0.8584\n",
            "Epoch 26/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3370 - accuracy: 0.8803 - val_loss: 0.3899 - val_accuracy: 0.8634\n",
            "Epoch 27/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3349 - accuracy: 0.8794 - val_loss: 0.3953 - val_accuracy: 0.8588\n",
            "Epoch 28/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3326 - accuracy: 0.8816 - val_loss: 0.3881 - val_accuracy: 0.8651\n",
            "Epoch 29/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3305 - accuracy: 0.8821 - val_loss: 0.3894 - val_accuracy: 0.8652\n",
            "Epoch 30/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3289 - accuracy: 0.8834 - val_loss: 0.3875 - val_accuracy: 0.8648\n",
            "Epoch 31/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8830 - val_loss: 0.3913 - val_accuracy: 0.8646\n",
            "Epoch 32/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3257 - accuracy: 0.8836 - val_loss: 0.3876 - val_accuracy: 0.8652\n",
            "Epoch 33/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3234 - accuracy: 0.8849 - val_loss: 0.3816 - val_accuracy: 0.8668\n",
            "Epoch 34/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3226 - accuracy: 0.8849 - val_loss: 0.3855 - val_accuracy: 0.8674\n",
            "Epoch 35/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3201 - accuracy: 0.8859 - val_loss: 0.3850 - val_accuracy: 0.8664\n",
            "Epoch 36/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3185 - accuracy: 0.8863 - val_loss: 0.3816 - val_accuracy: 0.8670\n",
            "Epoch 37/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3172 - accuracy: 0.8865 - val_loss: 0.3822 - val_accuracy: 0.8664\n",
            "Epoch 38/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3160 - accuracy: 0.8869 - val_loss: 0.3787 - val_accuracy: 0.8694\n",
            "Epoch 39/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3150 - accuracy: 0.8867 - val_loss: 0.3819 - val_accuracy: 0.8666\n",
            "Epoch 40/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3126 - accuracy: 0.8884 - val_loss: 0.3782 - val_accuracy: 0.8696\n",
            "Epoch 41/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3114 - accuracy: 0.8886 - val_loss: 0.3784 - val_accuracy: 0.8698\n",
            "Epoch 42/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3110 - accuracy: 0.8881 - val_loss: 0.3842 - val_accuracy: 0.8629\n",
            "Epoch 43/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3095 - accuracy: 0.8889 - val_loss: 0.3753 - val_accuracy: 0.8700\n",
            "Epoch 44/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3077 - accuracy: 0.8895 - val_loss: 0.3785 - val_accuracy: 0.8705\n",
            "Epoch 45/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3066 - accuracy: 0.8899 - val_loss: 0.3762 - val_accuracy: 0.8710\n",
            "Epoch 46/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3045 - accuracy: 0.8903 - val_loss: 0.3792 - val_accuracy: 0.8678\n",
            "Epoch 47/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3037 - accuracy: 0.8911 - val_loss: 0.3867 - val_accuracy: 0.8665\n",
            "Epoch 48/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3024 - accuracy: 0.8908 - val_loss: 0.3754 - val_accuracy: 0.8711\n",
            "Epoch 49/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3021 - accuracy: 0.8910 - val_loss: 0.3754 - val_accuracy: 0.8695\n",
            "Epoch 50/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3012 - accuracy: 0.8911 - val_loss: 0.3730 - val_accuracy: 0.8721\n",
            "Epoch 51/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3000 - accuracy: 0.8923 - val_loss: 0.3744 - val_accuracy: 0.8709\n",
            "Epoch 52/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2984 - accuracy: 0.8927 - val_loss: 0.3783 - val_accuracy: 0.8701\n",
            "Epoch 53/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2975 - accuracy: 0.8928 - val_loss: 0.3744 - val_accuracy: 0.8694\n",
            "Epoch 54/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2963 - accuracy: 0.8935 - val_loss: 0.3738 - val_accuracy: 0.8716\n",
            "Epoch 55/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2958 - accuracy: 0.8928 - val_loss: 0.3750 - val_accuracy: 0.8688\n",
            "Epoch 56/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2944 - accuracy: 0.8940 - val_loss: 0.3745 - val_accuracy: 0.8695\n",
            "Epoch 57/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2931 - accuracy: 0.8939 - val_loss: 0.3728 - val_accuracy: 0.8718\n",
            "Epoch 58/60\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2926 - accuracy: 0.8942 - val_loss: 0.3781 - val_accuracy: 0.8676\n",
            "Epoch 59/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2911 - accuracy: 0.8952 - val_loss: 0.3742 - val_accuracy: 0.8691\n",
            "Epoch 60/60\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2904 - accuracy: 0.8956 - val_loss: 0.3801 - val_accuracy: 0.8676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcea131aa00>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_0 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "], name= 'model_0')\n",
        "\n",
        "model_0.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(lr= 0.0001),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_0.fit(train_data,train_labels, epochs = 60, validation_data = (test_data_scaled, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medel_1: Dense model increasing layers from 16 to 256\n"
      ],
      "metadata": {
        "id": "CxhBnZ0rVXbS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b2xDBMysrX7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cfaf19-7fed-4957-d628-d6a1fe249802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5559 - accuracy: 0.7975 - val_loss: 0.4695 - val_accuracy: 0.8309\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4111 - accuracy: 0.8499 - val_loss: 0.4420 - val_accuracy: 0.8437\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3835 - accuracy: 0.8577 - val_loss: 0.4427 - val_accuracy: 0.8369\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3610 - accuracy: 0.8671 - val_loss: 0.4115 - val_accuracy: 0.8499\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3477 - accuracy: 0.8698 - val_loss: 0.3995 - val_accuracy: 0.8534\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3361 - accuracy: 0.8736 - val_loss: 0.3963 - val_accuracy: 0.8530\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3272 - accuracy: 0.8784 - val_loss: 0.3999 - val_accuracy: 0.8575\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3195 - accuracy: 0.8807 - val_loss: 0.3782 - val_accuracy: 0.8635\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3121 - accuracy: 0.8825 - val_loss: 0.3683 - val_accuracy: 0.8692\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3067 - accuracy: 0.8844 - val_loss: 0.3661 - val_accuracy: 0.8679\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2989 - accuracy: 0.8856 - val_loss: 0.3647 - val_accuracy: 0.8667\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2944 - accuracy: 0.8892 - val_loss: 0.3891 - val_accuracy: 0.8604\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2918 - accuracy: 0.8896 - val_loss: 0.3805 - val_accuracy: 0.8624\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2863 - accuracy: 0.8899 - val_loss: 0.3778 - val_accuracy: 0.8638\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2814 - accuracy: 0.8930 - val_loss: 0.3848 - val_accuracy: 0.8626\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2780 - accuracy: 0.8945 - val_loss: 0.3753 - val_accuracy: 0.8643\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2723 - accuracy: 0.8958 - val_loss: 0.3752 - val_accuracy: 0.8705\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2711 - accuracy: 0.8965 - val_loss: 0.3703 - val_accuracy: 0.8693\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2687 - accuracy: 0.8970 - val_loss: 0.3739 - val_accuracy: 0.8649\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2633 - accuracy: 0.9006 - val_loss: 0.3941 - val_accuracy: 0.8687\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2601 - accuracy: 0.9006 - val_loss: 0.3728 - val_accuracy: 0.8732\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2564 - accuracy: 0.9019 - val_loss: 0.3744 - val_accuracy: 0.8739\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2568 - accuracy: 0.9017 - val_loss: 0.3844 - val_accuracy: 0.8682\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2522 - accuracy: 0.9029 - val_loss: 0.4007 - val_accuracy: 0.8664\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2476 - accuracy: 0.9037 - val_loss: 0.3996 - val_accuracy: 0.8687\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2491 - accuracy: 0.9044 - val_loss: 0.3917 - val_accuracy: 0.8715\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2436 - accuracy: 0.9052 - val_loss: 0.3712 - val_accuracy: 0.8750\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2431 - accuracy: 0.9065 - val_loss: 0.4156 - val_accuracy: 0.8620\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2404 - accuracy: 0.9079 - val_loss: 0.3952 - val_accuracy: 0.8698\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2378 - accuracy: 0.9093 - val_loss: 0.4129 - val_accuracy: 0.8654\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcec0215040>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "], name= 'model_1')\n",
        "\n",
        "model_1.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_1.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Medel_2: Dense model decreasing layers from 256 to 16\n"
      ],
      "metadata": {
        "id": "uAEhFHdjVf_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape = (28,28,1)),\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
        "], name= 'model_2')\n",
        "\n",
        "model_2.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_2.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoLnBlShI7J9",
        "outputId": "fe4bb9df-74a3-48c0-94bd-4d5c48a135ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5467 - accuracy: 0.8065 - val_loss: 0.4274 - val_accuracy: 0.8482\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3780 - accuracy: 0.8615 - val_loss: 0.4542 - val_accuracy: 0.8470\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3394 - accuracy: 0.8752 - val_loss: 0.4064 - val_accuracy: 0.8520\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3162 - accuracy: 0.8849 - val_loss: 0.3724 - val_accuracy: 0.8656\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2970 - accuracy: 0.8903 - val_loss: 0.3527 - val_accuracy: 0.8735\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2818 - accuracy: 0.8941 - val_loss: 0.3619 - val_accuracy: 0.8686\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2699 - accuracy: 0.8988 - val_loss: 0.3730 - val_accuracy: 0.8653\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2602 - accuracy: 0.9031 - val_loss: 0.3438 - val_accuracy: 0.8763\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2502 - accuracy: 0.9057 - val_loss: 0.3400 - val_accuracy: 0.8819\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2401 - accuracy: 0.9094 - val_loss: 0.3459 - val_accuracy: 0.8831\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2323 - accuracy: 0.9120 - val_loss: 0.3323 - val_accuracy: 0.8842\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2266 - accuracy: 0.9150 - val_loss: 0.3649 - val_accuracy: 0.8723\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2212 - accuracy: 0.9168 - val_loss: 0.3401 - val_accuracy: 0.8851\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2145 - accuracy: 0.9186 - val_loss: 0.3368 - val_accuracy: 0.8858\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2062 - accuracy: 0.9231 - val_loss: 0.3255 - val_accuracy: 0.8852\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2006 - accuracy: 0.9243 - val_loss: 0.3710 - val_accuracy: 0.8777\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1941 - accuracy: 0.9258 - val_loss: 0.3594 - val_accuracy: 0.8893\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1907 - accuracy: 0.9274 - val_loss: 0.3527 - val_accuracy: 0.8883\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1846 - accuracy: 0.9296 - val_loss: 0.3586 - val_accuracy: 0.8924\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1827 - accuracy: 0.9309 - val_loss: 0.3775 - val_accuracy: 0.8833\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1761 - accuracy: 0.9337 - val_loss: 0.3506 - val_accuracy: 0.8882\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1707 - accuracy: 0.9358 - val_loss: 0.3744 - val_accuracy: 0.8931\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1682 - accuracy: 0.9356 - val_loss: 0.3715 - val_accuracy: 0.8869\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1650 - accuracy: 0.9376 - val_loss: 0.3894 - val_accuracy: 0.8895\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1609 - accuracy: 0.9385 - val_loss: 0.3816 - val_accuracy: 0.8903\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1569 - accuracy: 0.9411 - val_loss: 0.3733 - val_accuracy: 0.8930\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1563 - accuracy: 0.9406 - val_loss: 0.4309 - val_accuracy: 0.8871\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1543 - accuracy: 0.9409 - val_loss: 0.4088 - val_accuracy: 0.8899\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1484 - accuracy: 0.9441 - val_loss: 0.3734 - val_accuracy: 0.8977\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1484 - accuracy: 0.9447 - val_loss: 0.3907 - val_accuracy: 0.8925\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf30377e80>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mosel_3: Conv2D increasing layers from 8 to 32"
      ],
      "metadata": {
        "id": "LZf84TFvVseS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)\n",
        "model_3 = Sequential([\n",
        "  Conv2D(8, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(16, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "ksQiSrLRNOhV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "O42i6X5hN_hn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMzpjdb1OJ6_",
        "outputId": "2964d6eb-7464-4177-aa27-bfa477a99bbd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7190 - accuracy: 0.7370 - val_loss: 0.5621 - val_accuracy: 0.7942\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5134 - accuracy: 0.8151 - val_loss: 0.5364 - val_accuracy: 0.8089\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4687 - accuracy: 0.8303 - val_loss: 0.4711 - val_accuracy: 0.8291\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4404 - accuracy: 0.8417 - val_loss: 0.4525 - val_accuracy: 0.8396\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4232 - accuracy: 0.8471 - val_loss: 0.4493 - val_accuracy: 0.8411\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4067 - accuracy: 0.8532 - val_loss: 0.4654 - val_accuracy: 0.8347\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3925 - accuracy: 0.8584 - val_loss: 0.4319 - val_accuracy: 0.8430\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3802 - accuracy: 0.8631 - val_loss: 0.4264 - val_accuracy: 0.8482\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3706 - accuracy: 0.8661 - val_loss: 0.4037 - val_accuracy: 0.8555\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3622 - accuracy: 0.8683 - val_loss: 0.3991 - val_accuracy: 0.8584\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3541 - accuracy: 0.8720 - val_loss: 0.4127 - val_accuracy: 0.8545\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3459 - accuracy: 0.8743 - val_loss: 0.3920 - val_accuracy: 0.8608\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3409 - accuracy: 0.8761 - val_loss: 0.3763 - val_accuracy: 0.8675\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3341 - accuracy: 0.8784 - val_loss: 0.3800 - val_accuracy: 0.8640\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3290 - accuracy: 0.8801 - val_loss: 0.3722 - val_accuracy: 0.8691\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3242 - accuracy: 0.8817 - val_loss: 0.3888 - val_accuracy: 0.8606\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3195 - accuracy: 0.8826 - val_loss: 0.3800 - val_accuracy: 0.8663\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3157 - accuracy: 0.8838 - val_loss: 0.3811 - val_accuracy: 0.8675\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3126 - accuracy: 0.8866 - val_loss: 0.3682 - val_accuracy: 0.8697\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3088 - accuracy: 0.8885 - val_loss: 0.3658 - val_accuracy: 0.8705\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3051 - accuracy: 0.8878 - val_loss: 0.3916 - val_accuracy: 0.8619\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3027 - accuracy: 0.8896 - val_loss: 0.3779 - val_accuracy: 0.8652\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3000 - accuracy: 0.8887 - val_loss: 0.3749 - val_accuracy: 0.8647\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2977 - accuracy: 0.8909 - val_loss: 0.3836 - val_accuracy: 0.8685\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2955 - accuracy: 0.8916 - val_loss: 0.3777 - val_accuracy: 0.8665\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2936 - accuracy: 0.8917 - val_loss: 0.3672 - val_accuracy: 0.8687\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2917 - accuracy: 0.8922 - val_loss: 0.3699 - val_accuracy: 0.8693\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2885 - accuracy: 0.8939 - val_loss: 0.3793 - val_accuracy: 0.8649\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2866 - accuracy: 0.8951 - val_loss: 0.3637 - val_accuracy: 0.8744\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2851 - accuracy: 0.8948 - val_loss: 0.3728 - val_accuracy: 0.8688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcedcd8e040>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mosel_4: Conv2D decreasing layers from 32 to 8"
      ],
      "metadata": {
        "id": "5J77ElYQV4F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "# Create the model (this can be our baseline, a 3 layer Convolutional Neural Network)\n",
        "model_4 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(16, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(8, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_4.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_4.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnAlhiIaOOJA",
        "outputId": "f7720175-276b-4b12-e81e-ea4eae46dc74"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.1147 - accuracy: 0.6086 - val_loss: 0.7728 - val_accuracy: 0.7378\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7065 - accuracy: 0.7449 - val_loss: 0.7052 - val_accuracy: 0.7482\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6440 - accuracy: 0.7600 - val_loss: 0.6568 - val_accuracy: 0.7573\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6007 - accuracy: 0.7754 - val_loss: 0.6243 - val_accuracy: 0.7711\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5733 - accuracy: 0.7868 - val_loss: 0.5861 - val_accuracy: 0.7847\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5460 - accuracy: 0.7982 - val_loss: 0.5673 - val_accuracy: 0.7907\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5148 - accuracy: 0.8095 - val_loss: 0.5375 - val_accuracy: 0.8076\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4948 - accuracy: 0.8181 - val_loss: 0.5251 - val_accuracy: 0.8139\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4708 - accuracy: 0.8296 - val_loss: 0.4862 - val_accuracy: 0.8287\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4512 - accuracy: 0.8363 - val_loss: 0.4821 - val_accuracy: 0.8312\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4382 - accuracy: 0.8423 - val_loss: 0.4920 - val_accuracy: 0.8296\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4267 - accuracy: 0.8446 - val_loss: 0.4782 - val_accuracy: 0.8346\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.4199 - accuracy: 0.8468 - val_loss: 0.4855 - val_accuracy: 0.8302\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4141 - accuracy: 0.8491 - val_loss: 0.4577 - val_accuracy: 0.8397\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4078 - accuracy: 0.8528 - val_loss: 0.4581 - val_accuracy: 0.8417\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4021 - accuracy: 0.8535 - val_loss: 0.4492 - val_accuracy: 0.8457\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3973 - accuracy: 0.8555 - val_loss: 0.4608 - val_accuracy: 0.8423\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3935 - accuracy: 0.8576 - val_loss: 0.4485 - val_accuracy: 0.8457\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3886 - accuracy: 0.8583 - val_loss: 0.4563 - val_accuracy: 0.8427\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3845 - accuracy: 0.8611 - val_loss: 0.4387 - val_accuracy: 0.8481\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3797 - accuracy: 0.8623 - val_loss: 0.4584 - val_accuracy: 0.8419\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3772 - accuracy: 0.8637 - val_loss: 0.4498 - val_accuracy: 0.8472\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3737 - accuracy: 0.8639 - val_loss: 0.4416 - val_accuracy: 0.8492\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3716 - accuracy: 0.8651 - val_loss: 0.4349 - val_accuracy: 0.8507\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3694 - accuracy: 0.8659 - val_loss: 0.4418 - val_accuracy: 0.8496\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3668 - accuracy: 0.8669 - val_loss: 0.4279 - val_accuracy: 0.8543\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3633 - accuracy: 0.8684 - val_loss: 0.4287 - val_accuracy: 0.8517\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.3607 - accuracy: 0.8691 - val_loss: 0.4311 - val_accuracy: 0.8533\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3589 - accuracy: 0.8697 - val_loss: 0.4284 - val_accuracy: 0.8509\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3554 - accuracy: 0.8719 - val_loss: 0.4367 - val_accuracy: 0.8519\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcedcc53580>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_5: combnation of Con2d from 8 to 32 and Dens with 256 layers"
      ],
      "metadata": {
        "id": "x0KZcHWUV9iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_5 = Sequential([\n",
        "  Conv2D(8, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(16, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(32, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(256, activation = 'relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_5.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_5.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTFPPVRCPD-5",
        "outputId": "3adf40d7-e482-45f0-ca4a-a5ec195f0bf7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6846 - accuracy: 0.7475 - val_loss: 0.5214 - val_accuracy: 0.8105\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4777 - accuracy: 0.8269 - val_loss: 0.5164 - val_accuracy: 0.8140\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4262 - accuracy: 0.8440 - val_loss: 0.4337 - val_accuracy: 0.8401\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3918 - accuracy: 0.8564 - val_loss: 0.4008 - val_accuracy: 0.8519\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3697 - accuracy: 0.8637 - val_loss: 0.4050 - val_accuracy: 0.8588\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3522 - accuracy: 0.8702 - val_loss: 0.3988 - val_accuracy: 0.8527\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3367 - accuracy: 0.8759 - val_loss: 0.3911 - val_accuracy: 0.8522\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3241 - accuracy: 0.8789 - val_loss: 0.3986 - val_accuracy: 0.8531\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3150 - accuracy: 0.8833 - val_loss: 0.3526 - val_accuracy: 0.8682\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3061 - accuracy: 0.8852 - val_loss: 0.3701 - val_accuracy: 0.8634\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2971 - accuracy: 0.8895 - val_loss: 0.3483 - val_accuracy: 0.8730\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2888 - accuracy: 0.8927 - val_loss: 0.3460 - val_accuracy: 0.8719\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2811 - accuracy: 0.8943 - val_loss: 0.3544 - val_accuracy: 0.8692\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2748 - accuracy: 0.8973 - val_loss: 0.3432 - val_accuracy: 0.8760\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2696 - accuracy: 0.8981 - val_loss: 0.3355 - val_accuracy: 0.8788\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2634 - accuracy: 0.9017 - val_loss: 0.3441 - val_accuracy: 0.8768\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2594 - accuracy: 0.9029 - val_loss: 0.3585 - val_accuracy: 0.8777\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2570 - accuracy: 0.9039 - val_loss: 0.3396 - val_accuracy: 0.8791\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2506 - accuracy: 0.9065 - val_loss: 0.3449 - val_accuracy: 0.8763\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2458 - accuracy: 0.9071 - val_loss: 0.3484 - val_accuracy: 0.8779\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2421 - accuracy: 0.9087 - val_loss: 0.3711 - val_accuracy: 0.8709\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2394 - accuracy: 0.9089 - val_loss: 0.3521 - val_accuracy: 0.8789\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2348 - accuracy: 0.9109 - val_loss: 0.3490 - val_accuracy: 0.8794\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2320 - accuracy: 0.9101 - val_loss: 0.3657 - val_accuracy: 0.8784\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2269 - accuracy: 0.9131 - val_loss: 0.3646 - val_accuracy: 0.8801\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2267 - accuracy: 0.9125 - val_loss: 0.3491 - val_accuracy: 0.8801\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2236 - accuracy: 0.9147 - val_loss: 0.3605 - val_accuracy: 0.8788\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2185 - accuracy: 0.9169 - val_loss: 0.3728 - val_accuracy: 0.8712\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2163 - accuracy: 0.9173 - val_loss: 0.3693 - val_accuracy: 0.8799\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2138 - accuracy: 0.9182 - val_loss: 0.3763 - val_accuracy: 0.8756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcedc99d2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_5: combnation of Con2d from 8 to 32 and Dens with 128 layers"
      ],
      "metadata": {
        "id": "nMksUZV4WOXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_5 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(64, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(128, activation = 'relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_5.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_5.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dr1TEPWQUu4",
        "outputId": "9a2ef5c3-40c7-49ad-8bb3-18be6b59b641"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4529 - accuracy: 0.8359 - val_loss: 0.3469 - val_accuracy: 0.8753\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3024 - accuracy: 0.8896 - val_loss: 0.3455 - val_accuracy: 0.8723\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2569 - accuracy: 0.9039 - val_loss: 0.2866 - val_accuracy: 0.8920\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2233 - accuracy: 0.9171 - val_loss: 0.2624 - val_accuracy: 0.9068\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1980 - accuracy: 0.9259 - val_loss: 0.2643 - val_accuracy: 0.9038\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1745 - accuracy: 0.9351 - val_loss: 0.2783 - val_accuracy: 0.9010\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1550 - accuracy: 0.9414 - val_loss: 0.2625 - val_accuracy: 0.9090\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1356 - accuracy: 0.9486 - val_loss: 0.2756 - val_accuracy: 0.9105\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9547 - val_loss: 0.2709 - val_accuracy: 0.9133\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1077 - accuracy: 0.9593 - val_loss: 0.2946 - val_accuracy: 0.9079\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0944 - accuracy: 0.9647 - val_loss: 0.2889 - val_accuracy: 0.9166\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0824 - accuracy: 0.9690 - val_loss: 0.3245 - val_accuracy: 0.9144\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0718 - accuracy: 0.9729 - val_loss: 0.3654 - val_accuracy: 0.9112\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0656 - accuracy: 0.9749 - val_loss: 0.3839 - val_accuracy: 0.9120\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.3683 - val_accuracy: 0.9102\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0516 - accuracy: 0.9806 - val_loss: 0.4269 - val_accuracy: 0.9104\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0478 - accuracy: 0.9816 - val_loss: 0.4485 - val_accuracy: 0.9130\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.4812 - val_accuracy: 0.9080\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0385 - accuracy: 0.9859 - val_loss: 0.4669 - val_accuracy: 0.9091\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0359 - accuracy: 0.9870 - val_loss: 0.5227 - val_accuracy: 0.9087\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.5184 - val_accuracy: 0.9126\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.5353 - val_accuracy: 0.9113\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.5412 - val_accuracy: 0.9080\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0290 - accuracy: 0.9896 - val_loss: 0.5794 - val_accuracy: 0.9102\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0270 - accuracy: 0.9902 - val_loss: 0.5808 - val_accuracy: 0.9110\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.5672 - val_accuracy: 0.9087\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.6384 - val_accuracy: 0.9073\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.6326 - val_accuracy: 0.9101\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.6562 - val_accuracy: 0.9119\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.7435 - val_accuracy: 0.9108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcedc7e8250>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model_6: combnation of Con2d from 8 to 32 and Dens with 128 layers and same padding"
      ],
      "metadata": {
        "id": "Rjn--ZBgWTYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_6 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu',padding='same', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(64, 3,padding='same', activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(128, activation = 'relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_6.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_6.fit(train_data,train_labels, epochs = 30, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cI9GrsqU2P-",
        "outputId": "252a1e1d-1f62-4542-d31a-c100388603af"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3921 - accuracy: 0.8582 - val_loss: 0.3140 - val_accuracy: 0.8882\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2576 - accuracy: 0.9054 - val_loss: 0.3268 - val_accuracy: 0.8816\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2143 - accuracy: 0.9207 - val_loss: 0.2527 - val_accuracy: 0.9074\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1810 - accuracy: 0.9323 - val_loss: 0.2331 - val_accuracy: 0.9154\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1557 - accuracy: 0.9425 - val_loss: 0.2348 - val_accuracy: 0.9160\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1315 - accuracy: 0.9500 - val_loss: 0.2725 - val_accuracy: 0.9096\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1099 - accuracy: 0.9590 - val_loss: 0.2473 - val_accuracy: 0.9206\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0905 - accuracy: 0.9664 - val_loss: 0.2680 - val_accuracy: 0.9182\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0770 - accuracy: 0.9711 - val_loss: 0.2783 - val_accuracy: 0.9201\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 0.3172 - val_accuracy: 0.9219\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0553 - accuracy: 0.9794 - val_loss: 0.3218 - val_accuracy: 0.9218\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0478 - accuracy: 0.9819 - val_loss: 0.3652 - val_accuracy: 0.9190\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0397 - accuracy: 0.9856 - val_loss: 0.3858 - val_accuracy: 0.9203\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0349 - accuracy: 0.9870 - val_loss: 0.4460 - val_accuracy: 0.9127\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.4118 - val_accuracy: 0.9191\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.4466 - val_accuracy: 0.9171\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 0.4909 - val_accuracy: 0.9175\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0267 - accuracy: 0.9904 - val_loss: 0.5139 - val_accuracy: 0.9210\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.5279 - val_accuracy: 0.9166\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.5588 - val_accuracy: 0.9192\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.5513 - val_accuracy: 0.9118\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.6211 - val_accuracy: 0.9192\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.5875 - val_accuracy: 0.9184\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.6518 - val_accuracy: 0.9165\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.6589 - val_accuracy: 0.9164\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.6373 - val_accuracy: 0.9133\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.6585 - val_accuracy: 0.9195\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.6623 - val_accuracy: 0.9183\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.7025 - val_accuracy: 0.9151\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.7181 - val_accuracy: 0.9186\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcedc6c0760>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6 = Sequential([\n",
        "  Conv2D(32, 3, activation='relu',padding='same', input_shape=(28, 28, 1)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(64, 3,padding='same', activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(128, activation = 'relu'),\n",
        "  Dense(256, activation = 'relu'),\n",
        "  Dense(512, activation = 'relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_6.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "model_6.fit(train_data,train_labels, epochs = 50, validation_data = (test_data_scaled, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsShg297WlFy",
        "outputId": "379ecc23-fb12-4a60-dc01-32a22e325d8a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4133 - accuracy: 0.8469 - val_loss: 0.3333 - val_accuracy: 0.8835\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2623 - accuracy: 0.9023 - val_loss: 0.3463 - val_accuracy: 0.8800\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2187 - accuracy: 0.9200 - val_loss: 0.2537 - val_accuracy: 0.9070\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1897 - accuracy: 0.9297 - val_loss: 0.2731 - val_accuracy: 0.9072\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1643 - accuracy: 0.9389 - val_loss: 0.2660 - val_accuracy: 0.9079\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1442 - accuracy: 0.9456 - val_loss: 0.2519 - val_accuracy: 0.9141\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1245 - accuracy: 0.9529 - val_loss: 0.2730 - val_accuracy: 0.9149\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1087 - accuracy: 0.9596 - val_loss: 0.2777 - val_accuracy: 0.9187\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0976 - accuracy: 0.9625 - val_loss: 0.3102 - val_accuracy: 0.9177\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0851 - accuracy: 0.9681 - val_loss: 0.3275 - val_accuracy: 0.9184\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.3287 - val_accuracy: 0.9160\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0670 - accuracy: 0.9744 - val_loss: 0.3510 - val_accuracy: 0.9202\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0624 - accuracy: 0.9773 - val_loss: 0.4190 - val_accuracy: 0.9148\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0576 - accuracy: 0.9783 - val_loss: 0.4137 - val_accuracy: 0.9171\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0515 - accuracy: 0.9815 - val_loss: 0.4146 - val_accuracy: 0.9170\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.4557 - val_accuracy: 0.9091\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0457 - accuracy: 0.9831 - val_loss: 0.5047 - val_accuracy: 0.9153\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0441 - accuracy: 0.9844 - val_loss: 0.4665 - val_accuracy: 0.9131\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0370 - accuracy: 0.9869 - val_loss: 0.4614 - val_accuracy: 0.9136\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.4406 - val_accuracy: 0.9144\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.5229 - val_accuracy: 0.9140\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.5344 - val_accuracy: 0.9141\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.5828 - val_accuracy: 0.9092\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.5422 - val_accuracy: 0.9170\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.5378 - val_accuracy: 0.9182\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0290 - accuracy: 0.9903 - val_loss: 0.5664 - val_accuracy: 0.9129\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.6196 - val_accuracy: 0.9081\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.6051 - val_accuracy: 0.9125\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.6465 - val_accuracy: 0.9150\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.7355 - val_accuracy: 0.9155\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 0.6266 - val_accuracy: 0.9173\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.7192 - val_accuracy: 0.9143\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.6844 - val_accuracy: 0.9147\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.6831 - val_accuracy: 0.9129\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.6912 - val_accuracy: 0.9137\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.7007 - val_accuracy: 0.9145\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 0.5826 - val_accuracy: 0.9143\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.8558 - val_accuracy: 0.9141\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.9501 - val_accuracy: 0.9124\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.7304 - val_accuracy: 0.9158\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.7978 - val_accuracy: 0.9148\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.7622 - val_accuracy: 0.9134\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.8113 - val_accuracy: 0.9142\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.8948 - val_accuracy: 0.9149\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0194 - accuracy: 0.9945 - val_loss: 0.7419 - val_accuracy: 0.9181\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.7848 - val_accuracy: 0.9131\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.9554 - val_accuracy: 0.9128\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.8379 - val_accuracy: 0.9152\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.8542 - val_accuracy: 0.9159\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.8299 - val_accuracy: 0.9130\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fceac87f040>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conclusion\n",
        "\n",
        "We can conclude that the combination of Dense and Conv 2d with the same padding work the best."
      ],
      "metadata": {
        "id": "r_Uc3FyWWbFG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "treIVvBNWiva"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUIPp09scgxCWCUWq+284T",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}